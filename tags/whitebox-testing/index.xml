<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Whitebox Testing on chasepd</title><link>https://chasepd.github.io/tags/whitebox-testing/</link><description>Recent content in Whitebox Testing on chasepd</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 11 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://chasepd.github.io/tags/whitebox-testing/index.xml" rel="self" type="application/rss+xml"/><item><title>Leveraging AI Coding Tools for Security Code Review and Whitebox Penetration Testing</title><link>https://chasepd.github.io/posts/ai-tools-for-code-review/</link><pubDate>Fri, 11 Jul 2025 00:00:00 +0000</pubDate><guid>https://chasepd.github.io/posts/ai-tools-for-code-review/</guid><description>Introduction AI coding tools have fundamentally changed how developers write code, but their impact on security engineering workflows is still being explored. As someone who spends significant time reviewing code for vulnerabilities and conducting whitebox penetration tests, I&amp;rsquo;ve found that tools like Cursor can significantly enhance both the speed and thoroughness of security assessments.
This post covers practical strategies for integrating AI coding assistants into security code review and whitebox penetration testing workflows, based on real-world experience using these tools in production environments.</description></item></channel></rss>